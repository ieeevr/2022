id,title,,,abstract,authors,url
J1010,SEAR: Scaling Experiences in Multi-user Augmented Reality,,,"In this paper, we present SEAR, a collaborative framework for Scaling Experiences in multi-user Augmented Reality (AR). Most AR systems benefit from computer vision algorithms to detect/classify/recognize physical objects for augmentation. A widely-used acceleration method is to offload compute-intensive tasks to the network edge. However, we show that the end-to-end latency, an important metric of mobile AR, may dramatically increase when offloading tasks from a large number of concurrent users. SEAR tackles this scalability issue through the innovation of a lightweight collaborative local cache. We build a prototype of SEAR to demonstrate its efficacy in scaling AR experiences.","Wenxiao ZHANG, Bo Han, Pan Hui",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150467
J1012,Synthesizing Personalized Construction Safety Training Scenarios for VR Training,,,"Construction industry has the largest number of preventable fatal injuries, providing effective safety training practices can play a significant role in reducing the number of fatalities. Building on recent advancements in virtual reality-based training, we devised a novel approach to synthesize construction safety training scenarios to train users on how to proficiently inspect the potential hazards on construction sites in virtual reality. Given the training specifications such as individual training preferences and target training time, we synthesize personalized VR training scenarios through an optimization approach. We validated our approach by conducting user studies where users went through our personalized VR training, general VR training, or conventional slides training. The results show that our personalized VR training approach can more effectively train users to improve their construction hazard inspection skills.","Wanwan Li, Haikun Huang, Tomay Solomon, Behzad Esmaeili, Lap-Fai Yu",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150510
J1023,ScanGAN360: A Generative Model of Realistic Scanpaths for 360&#176; Images,,,"We present ScanGAN360, a new generative adversarial approach to address this problem. We propose a novel loss function based on dynamic time warping and tailor our network to the specifics of 360&#176; images. The quality of our generated scanpaths outperforms competing approaches by a large margin, and is almost on par with the human baseline. ScanGAN360 allows fast simulation of large numbers of virtual observers, whose behavior mimics real users, enabling a better understanding of gaze behavior, facilitating experimentation, and aiding novel applications in virtual reality and beyond.","Daniel Martin, Ana Serrano, Alexander William Bergman, Gordon Wetzstein, Belen Masia",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150502
J1024,"The Effect of Context Switching, Focal Switching Distance, Binocular and Monocular Viewing, and Transient Focal Blur on Human Performance in Optical See-Through Augmented Reality",,,"In optical see-through augmented reality (AR), information is often distributed between real and virtual contexts, and often appears at different distances from the user. To integrate information, users must repeatedly switch context and change focal distance. Previously, Gabbard, Mehra, and Swan (2018) examined these issues, using a text-based visual search task on a monocular, optical see-through AR display. Our study partially replicated and extended this task on a custom-built AR Haploscope for both monocular and binocular viewings. Results establishes that context switching, focal distance switching, and transient focal blur remain important AR user interface design issues.","Mohammed Safayet Arefin, Nate Phillips, Alexander Plopski, Joseph L Gabbard, J. Edward Swan",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150503
J1026,FrictShoes: Providing Multilevel Nonuniform Friction Feedback on Shoes in VR,,,"We propose a wearable device, FrictShoes a pair of foot accessories, to provide multilevel nonuniform friction feedback to feet. By independently controlling six brakes on six wheels underneath each FrictShoe, the friction levels of the wheels from each could be either matched or to vary. We conducted user studies to understand users' distinguishability of friction force magnitudes (or levels), realize how users adjust and map the multilevel nonuniform friction patterns to common VR terrains or ground textures, and evaluate the performance of the proposed feedback to the feet as if walking on different terrains or ground textures in VR.","Chih-An Tsao, Tzu-Chun Wu, Hsin-Ruey Tsai, Tzu-Yun Wei, Fang-Ying Liao, Sean Chapman, Bing-Yu Chen",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150492
J1039,Remote research on locomotion interfaces for virtual reality: Replication of lab-based research on the teleporting interface,,,"Researchers can now recruit virtual reality (VR) equipment owners to participate remotely. Yet, there are many differences between lab and home environments, as well as differences between participant samples recruited for lab and remote studies. This project replicates a lab-based experiment on VR locomotion interfaces using a remote sample. Participants completed a triangle-completion task (travel two path legs, then point to the path origin) in a remote, unsupervised setting. Locomotion was accomplished using two versions of the teleporting interface varying in available rotational self-motion cues. Remote results largely mirrored lab results, with better performance when rotational cues were available.","Jonathan Kelly, Melynda Hoover, Taylor A Doty, Alex Renner, Moriah Zimmerman, Kimberly Knuth, Lucia Cherep, Stephen B. Gilbert",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150475
J1050,Do You Need Another Hand? Investigating Dual Body Representations During Anisomorphic 3D Manipulation,,,"Manipulation techniques that distort motion can negatively impact the sense of embodiment as they create a mismatch between the real action and the displayed action. In this paper, we propose to use a dual representation during anisomorphic interaction. A co-located representation reproduces the users' motion, while an interactive representation is used for distorted interaction. We conducted two experiments, investigating the use of dual representations with amplified motion (with the Go-Go technique) and decreased motion (with the PRISM technique). Two visual appearances for the interactive representation and the co-located one were explored (ghost and realistic). ","Diane Dewez, Ludovic Hoyet, Anatole L&eacute;cuyer, Ferran Argelaguet Sanz",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150501
J1072,Mood-Driven Colorization of Virtual Indoor Scenes,,,"A challenging task in virtual scene design for Virtual Reality (VR) is invoking particular moods in viewers. The subjective nature of moods brings uncertainty to this purpose. We propose a novel approach for automatic color adjustment of textures for objects in virtual indoor scenes, enabling them to match target moods. A dataset of 25,000 indoor environment images was used to train a classifier with features extracted via deep learning. We use an optimization process that colorizes virtual scenes automatically according to the target mood. Our approach was tested on four indoor scenes used in user studies with a VR headset.","Michael S Solah, Haikun Huang, Jiachuan Sheng, Tian Feng, Marc Pomplun, Lap-Fai Yu",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150513
J1082,PoVRPoint: Authoring Presentations in Mobile Virtual Reality,,,"We propose PoVRPoint - a set of tools coupling pen- and touch-based editing of presentations on mobile touch devices with the interaction capabilities afforded by VR. We study the utility of extended display space to assist users in identifying target slides, supporting spatial manipulation of slide-content, creating animations, and facilitating arrangements of multiple, possibly occluded objects. Among other things, our results indicate that the three-dimensional view in VR enables significantly faster object reordering in the presence of occlusion compared to two baseline interfaces. A user study further confirmed that our interaction techniques were found to be usable and enjoyable.","Verena Biener, Travis Gesslein, Daniel Schneider, Felix Kawala, Alexander Otte, Per Ola Kristensson, Michel Pahud, Eyal Ofek, Cuauhtli Campos, Matjazz Kljun, Klen &#x10C;opi&#x10D; Pucihar, Jens Grubert",
J1087,Studying the Effects of Congruence of Auditory and Visual Stimuli on Virtual Reality Experiences,,,"This paper explores how the congruence between auditory and visual (AV) stimuli, which are the sensory stimuli typically provided by VR devices. We defined the types of (in)congruence between AV stimuli, and then designed 12 virtual spaces with different degrees of congruence between AV stimuli with evaluating user experience changes. We observed the following key findings: 1) there is a limit to the degree of temporal or spatial incongruence that can be tolerated&#59; 2) users are tolerant of semantic incongruence&#59; 3) a simulation that considers synesthetic congruence contributes to the user's sense of immersion and presence.","Hayeon Kim, In-Kwon Lee",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150514
J1089,Comparing Direct and Indirect Methods of Audio Quality Evaluation in Virtual Reality Scenes of Varying Complexity,,,"This study uses four subjective audio quality evaluation methods (viz. multiple-stimulus with and without reference for direct scaling, and rank-order elimination and pairwise comparison for indirect scaling) to investigate the contributing factors present in multi-modal 6-DoF VR on quality ratings of real-time audio rendering. Five scenes were designed for evaluation with various amounts of user interactivity and complexity. Our results show rank-order elimination proved to be the fastest method, required the least amount of repetitive motion, and yielded the highest discrimination between spatial conditions. Ratings across scenes indicate complex scenes and interactive aspects of 6-DoF VR can impede quality judgments.","Thomas Robotham, Olli S. Rummukainen, Miriam Kurz, Marie Eckert, Emanu&euml;l A. P. Habets",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150491
J1093,The Impact of Embodiment and Avatar Sizing on Personal Space in Immersive Virtual Environments,,,"Our work examines how degree of embodiment and avatar sizing affect the way personal space is perceived in virtual reality. We look at two components of personal space: interpersonal and peripersonal space. We hypothesized that higher levels of embodiment would result in differing measures of interpersonal and peripersonal space, and that, only interpersonal space would change with arm length. We found that interpersonal and peripersonal space change in the presence of differing levels of embodiment, and that only interpersonal space is sensitive to changes in arm dimension. These findings provide understanding for improved design of social interaction in virtual environments.","Lauren Buck, Soumyajit Chakraborty, Bobby Bodenheimer",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150483
J1099,Stereopsis Only: Validation of a Monocular Depth Cues Reduced Gamified Virtual Reality with Reaction Time Measurement,,,"Visuomotor task performance is limited in absence of binocular cues, e.g. when the visual system is affected by a disorder like amblyopia. Conventional amblyopia treatment occludes the healthy eye, however, resulting in poor stereopsis improvements. Therefore, binocular treatments equilibrate both eyes' visual input. Most approaches use divided stimuli which do not account for loss of stereopsis. We created a Virtual Reality with reduced monocular depth cues in which a stereoscopic task is shown to both eyes simultaneously. In a study with 18 participants, the number of correct responses reduced from 90% under binocular vision to 50% under monocular vision.","Wolfgang Andreas Mehringer, Markus Wirth, Daniel Roth, Georg Michelson, Bjoern M Eskofier",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150486
J1111,Dynamic Multi-Projection Mapping Based on Parallel Intensity Control,,,"Projection mapping using multiple projectors is promising for spatial augmented reality&#59; however, it is difficult to apply it to dynamic scenes. This is because it is hard for the conventional method to reduce the latency from motion to projection. To mitigate this, we propose a novel method of controlling the intensity based on a pixel-parallel calculation for each projector with low latency. Additionally, our pixel-parallel calculation method allows a distributed system configuration, such that the number of projectors can be increased to form a network. We demonstrate a seamless mapping into dynamic scenes at 360 fps with a 9.5-ms latency using ten cameras and four projectors.","Takashi Nomoto, Wanlong Li, Hao-Lun Peng, Yoshihiro Watanabe",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150488
J1129,Augmenting Immersive Telepresence Experience with a Virtual Body,,,"We propose augmenting immersive telepresence by adding a virtual body, representing the user's own arm motions, as realized through a head-mounted display and a 360-degree camera. We conducted a study where participants were telepresent through a head-mounted display at a researcher's physical location, who interacted with them and prompted for reactions. The results showed contradiction between pilot and confirmatory studies, with at best weak evidence in increase of presence and preference of the virtual body. Further analysis suggests that the quality and style of the virtual arms led to individual differences, which subsequently moderated feelings of presence.","Nikunj Arora, Markku Suomalainen, Matti Pouke, Evan G Center, Katherine J. Mimnaugh, Alexis P Chambers, Pauli Sakaria Pouke, Steven LaValle",
J1131,VirtualCube: An Immersive 3D Video Communication System,,,"The VirtualCube system is a 3D video conference system that attempts to overcome some limitations of conventional technologies. The physical setup of VirtualCube is a standardized cubicle installed with off-the-shelf hardware including 3 TV displays and 6 RGBD cameras. With high-quality 3D capturing and rendering algorithm, the system teleports the remote participants into a virtual meeting room to achieve immersive in-person meeting experience with correct eye gaze. A set of VirtualCubes can be easily assembled into a V-Cube Assembly to model different video communication and shared workspace scenarios, as if all participants were in the same room.","Yizhong Zhang, Jiaolong Yang, Zhen Liu, Ruicheng Wang, Guojun Chen, Xin Tong, Baining Guo",
J1151,Instant Reality: Gaze-Contingent Perceptual Optimization for 3D Virtual Reality Streaming,,,"To advance VR applications in a cloud-edge setting, we propose a perceptually-optimized progressive 3D streaming method for spatial quality and temporal consistency. Our model schedules the streaming assets for optimal spatial-temporal quality based on human visual mechanisms. Subjective studies and objective analysis demonstrate the framework's enhanced visual quality and temporal consistency than alternative solutions. We envision our framework allowing future efficient immersive streaming applications without compromising high visual quality and interactivity, such as those in esports and teleconference.","Shaoyu Chen, Budmonde Duinkharjav, Xin Sun, Li-Yi Wei, Stefano Petrangeli, Jose Echevarria, Claudio Silva, Qi Sun",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150522
J1154,A Virtual Reality Based System for the Screening and Classification of Autism,,,"Autism Spectrum Disorders (ASD) - also known solely as Autism or Autism Spectrum Conditions (ASC) - are a neurodevelopmental disorder (ICD-11 6A02) that is associated with characteristic deficits in social interaction and altered communicative behavior patterns. As a consequence, many autistic individuals may struggle in everyday life, which sometimes manifests in depression, unemployment, or addiction. One crucial problem in patient support and treatment is the long waiting time to diagnosis, which was approximated to 13 months on average. Yet, the earlier an intervention can take place the better the patient can be supported, which was identified as a crucial factor. We propose a system to support the screening of ASD based on a virtual reality (VR) social interaction, namely a shopping experience, with an embodied agent. During this everyday interaction, behavioral responses are tracked and recorded. We analyze this behavior with machine learning approaches to classify participants from an ASD group in comparison to a typically developed (TD) individuals control sample with high accuracy, demonstrating the feasibility of the approach. We believe that such tools can strongly impact the way mental disorders are assessed and may help to further find objective criteria and categorization.","Marta Robles, Negar Namdarian Nosratabadi, Julia Otto, Evelin Wassiljew, Nassir Navab, Christine Falter Wagner, Daniel Roth",https://doi.org/10.1109/TVCG.2022.3150489
J1167,Effects of Transparency on Perceived Humanness: Implications for Rendering Skin Tones Using Optical See-Through Displays,,,"Current optical see-through displays in the field of augmented reality are limited in their ability to display colors with low lightness in the hue, saturation, lightness (HSL) color space, causing such colors to appear transparent. This hardware limitation may add unintended bias into scenarios with virtual humans. We present an exploratory user study investigating whether differing opacity levels result in dehumanizing avatar and human faces. Results support that dehumanization occurs as opacity decreases. This suggests that in similar lighting, low lightness skin tones (e.g., Black faces) will be viewed as less human than high lightness skin tones (e.g., White faces). ","Tabitha C. Peck, Jessica J Good, Austin Erickson, Isaac M Bynum, Gerd Bruder",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150521
J1226,Duplicated Reality for Co-located Augmented Reality Collaboration,,,"When multiple users collaborate in the same space with Augmented Reality, they often encounter conflicting intentions regarding the occupation of the working area. For relaxing constraints of physical co-location, we propose Duplicated Reality, where a digital copy of a 3D region of interest is reconstructed in real-time and visualized through Augmented Reality. We compare the proposed method to an in-situ augmentation. The result indicates almost identical metrics, except a decrease in the consulter's awareness of co-located users when using our method. Duplicating the working area into a designated consulting area opens up new paradigms for future co-located Augmented Reality systems.","Kevin Yu, Ulrich Eck, Frieder Pankratz, Marc Lazarovici, Dirk Wilhelm, Nassir Navab",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150520
J1232,Prepare for Ludicrous Speed: Marker-based Instantaneous Binocular Rolling Shutter Localization,,,"We propose a marker-based geometric framework for the high-frequency absolute pose estimation of a binocular camera system by using the data captured during the exposure of a single rolling shutter scanline. We leverage the projective invariants of a planar pattern to define a geometric reference and determine 2D-3D correspondences from edge measurements in individual scanlines. To tackle the ensuing multi-view estimation problem, achieve real-time operation, and minimize latency, we develop a pair of custom solvers leveraging our geometric setup. We demonstrate the effectiveness of our approach with an FPGA implementation achieving a localization throughput of 129.6 KHz with 1.5us latency.","Juan Carlos Dibene Simental, Yazmin Maldonado, Leonardo Trujillo, Enrique Dunn",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150485
J1239,Robust Tightly-Coupled Visual-Inertial Odometry with Pre-built Maps in High Latency Situations,,,"In this paper, we present a novel monocular visual-inertial odometry system with the pre-built maps deployed on the remote server. By coupling VIO with geometric priors from pre-built maps, our system can tolerate the high latency and low frequency of global localization service. Firstly, sparse point clouds are obtained from the dense mesh according to the localization results. The sparse point clouds are directly used for feature tracking and state update of VIO to suppress the drift accumulation. Both the experiments on datasets and the real-time AR demo show that our method outperforms the state-of-the-art methods.","Hujun Bao, Weijian Xie, Quanhao Qian, Danpeng Chen, Shangjin Zhai, Nan Wang, Guofeng Zhang",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150495
J1244,Online Projector Deblurring Using a Convolutional Neural Network,,,"Projector deblurring is an important technology for dynamic projection mapping (PM), where the distance between a projector and a projection surface changes in time. However, conventional deblurring techniques do not support dynamic PM because they need to project calibration patterns to estimate the amount of defocus blur each time the surface moves. We present a deep neural network that can compensate for defocus blur in dynamic PM without projecting calibration patterns. We also propose a pseudo-projection technique for synthesizing physically plausible training data. Both simulation and physical PM experiments showed that our technique alleviated the defocus blur in dynamic PM.","Yuta Kageyama, Daisuke Iwai, Kosuke Sato",https://doi.org/10.1109/TVCG.2022.3150465
J1302,Omnidirectional Galvanic Vestibular Stimulation in Virtual Reality,,,"Cybersickness often taints virtual experiences. Its source can be associated to the perceptual mismatch happening when our eyes tell us we are moving while we are, in fact, at rest. We reconcile the signals from our senses by using omnidirectional galvanic vestibular stimulation (GVS), stimulating the vestibular canals behind our ears with low-current electrical signals specifically attuned to the visually displayed camera motion. We describe how to calibrate and generate the appropriate GVS signals in real-time for pre-recorded omnidirectional videos exhibiting ego-motion in all three spatial directions, and prove that it significantly reduces discomfort for cybersickness-susceptible VR users. ","Colin Groth, Jan-Philipp Tauscher, Nikkel Heesen, Max Hattenbach, Susana Castillo, Marcus Magnor",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150506
J1310,The One-Man-Crowd: Single User Generation of Crowd Motions Using Virtual Reality,,,"Crowd motion data is fundamental for understanding and simulating crowd behaviours. Such data is usually collected through controlled experiments and is scarce due to difficulties involved in its gathering. In this work, we propose a novel Virtual Reality based approach for the acquisition of crowd motion data, which immerses a single user in virtual scenarios to act each crowd member. We validate our approach by replicating three real experiments, and compare the results. Using our approach, realistic collective behaviours can naturally emerge, even though with lower behavioural variety. These results provide valuable insights to virtual crowd experiences, and reveal key directions for further improvements.","Tairan Yin, Ludovic Hoyet, Marc Christie, Marie-Paule R. Cani, Julien Pettr&eacute;",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150507
J1327,Video See-Through Mixed Reality with Focus Cues,,,"We introduce the first approach to video see-through mixed reality with support for focus cues. By combining the flexibility to adjust the focus distance found in varifocal designs with the robustness to eye-tracking error of multifocal designs, our novel display architecture delivers focus cues over large workspaces. In particular, we introduce gaze-contingent layered displays and mixed reality focal stacks, an efficient representation of mixed reality content that lends itself to fast processing for driving layered displays in real time. We evaluate this approach by building an end-to-end pipeline for capture, render, and display of focus cues in video see-through displays.","Christoph Ebner, Shohei Mori, Peter Mohr, Yifan (Evan) Peng, Dieter Schmalstieg, Gordon Wetzstein, Denis Kalkofen",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150504
J1331,Breaking Plausibility Without Breaking Presence - Evidence For The Multi-Layer Nature Of Plausibility,,,"Recently, a novel theoretical model introduced coherence and plausibility as the essential conditions of XR experiences. Plausibility results from multi-layer (cognitive, perceptual, and sensational) coherence activation. We utilized breaks in plausibility (analogous to breaks in presence) by introducing incoherence on the perceptual and cognitive layer. A simulation of gravity-defying objects, i.e., the perceptual manipulation, broke plausibility, however, not presence. Simultaneously, the cognitive manipulation, presented as storyline framing, was too weak to counteract the strong bottom-up inconsistencies. Both results confirm the predictions of the novel model, incorporating well-known top-down and bottom-up rivalries and a theorized increased independence between plausibility and presence.","Larissa Br&uuml;bach, Franziska Westermeier, Carolin Wienrich, Marc Erich Latoschik",https://doi.org/10.1109/TVCG.2022.3150496
J1334,Adaptive Redirection: A Context-Aware Redirected Walking Meta-Strategy,,,"This work establishes the theoretical foundations for adaptive redirection, a meta-strategy that switches between a suite of redirected walking strategies with a priori knowledge of their performance under the various circumstances. We also introduce a novel static planning strategy that optimizes gain parameters for a predetermined virtual path and conduct a simulation-based experiment that demonstrates how adaptation rules can be determined empirically using machine learning. Adaptive redirection provides a foundation for making redirected walking work in practice and can be extended to improve performance in the future as new techniques are integrated into the framework.","Mahdi Azmandian, Rhys Yahata, Timofey Grechkin, Evan Suma Rosenberg",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150500
J1335,Validating Simulation-Based Evaluation of Redirected Walking Systems,,,"We present an experiment comparing redirected walking simulation and live user data to understand interaction between locomotion behavior and redirection gains at a micro-level (across small path segments) and macro-level (across an entire experience). The results identify specific properties of locomotion behavior that influence the application of redirected walking. Overall, we found that the simulation provided a conservative estimate of the average performance with real users and observed that performance trends when comparing two redirected walking algorithms were preserved. In general, these results indicate that simulation is an empirically valid evaluation methodology for redirected walking algorithms.","Mahdi Azmandian, Rhys Yahata, Timofey Grechkin, Jerald Thomas, Evan Suma Rosenberg",https://doi.ieeecomputersociety.org/10.1109/TVCG.2022.3150466
